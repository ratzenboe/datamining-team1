{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook, 'kernels' folder, nrkmeans.py and PreDeCon.py have to be in tudataset/tud_benchmark/ directory\n",
    "\n",
    "# This means that you have to first download the TUDataset Repository e.g. with\n",
    "# git clone https://github.com/chrsmrrs/tudataset.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining 20W group programming assignment\n",
    "\n",
    "### Group 1\n",
    "### dataset - IMDB_Binary\n",
    "### algorithm - PreDeCon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "21xKJ1tsqNAM"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/deprecation.py:143: FutureWarning: The sklearn.cluster.k_means_ module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.cluster. Anything that cannot be imported from sklearn.cluster is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import auxiliarymethods.auxiliary_methods as aux\n",
    "from copy import deepcopy\n",
    "from auxiliarymethods import datasets as dp\n",
    "from auxiliarymethods.reader import tud_to_networkx\n",
    "from matplotlib import pyplot as plt\n",
    "import networkx as nx\n",
    "from nrkmeans import NrKmeans\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from PreDeCon import PreDeCon\n",
    "from scipy.sparse import load_npz\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import SpectralClustering, KMeans, AgglomerativeClustering, DBSCAN, FeatureAgglomeration, AffinityPropagation, SpectralClustering\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.decomposition import KernelPCA, TruncatedSVD, PCA\n",
    "from sklearn.metrics import normalized_mutual_info_score\n",
    "from sklearn.neighbors import LocalOutlierFactor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility functions\n",
    "def load_csv(path):\n",
    "    return np.loadtxt(path, delimiter=\";\")\n",
    "\n",
    "def load_sparse(path):\n",
    "    return load_npz(path)\n",
    "\n",
    "def select_from_list(l, indices):\n",
    "    return [l[i] for i in indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVrEb7GBq_cP"
   },
   "source": [
    "## Example usage for gram matrix and sparse matrix with Weisfeiler-Lehman kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load from  kernels/without_labels\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor iterations in range(1,6):\\n    # 0 taking just the nodelabels themselves into account; \\n     # 1 considers nearest-neighbours, 2 one layer deeper and so on\\n    # play with this parameter to create a new kernel!\\n    print(\"##################################\")\\n    print(\"Dataset \", dataset)\\n    print(\"Iteration \", iterations)\\n    print(\"##################################\")\\n\\n    #Gram Matrix for the Weisfeiler-Lehman subtree kernel\\n    gram = load_csv(os.path.join(base_path,f\"{dataset}_gram_matrix_wl{iterations}.csv\"))\\n    gram = aux.normalize_gram_matrix(gram)\\n\\n    #Sparse Vectors for the Weisfeiler-Lehmann subtree kernel\\n    vec = load_sparse(os.path.join(base_path,f\"{dataset}_vectors_wl{iterations}.npz\"))\\n    print(gram.shape, vec.shape)\\n\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # This code was used to get the results for each data set above:\n",
    "# # Get some initial results for each data set\n",
    "# # This will plot all representations and cluster these with Spectral Clustering and Subkmeans\n",
    "# # In your case you might only want to run your data set\n",
    "\n",
    "use_edge_labels = False\n",
    "base_path = os.path.join(\"kernels\", \"without_labels\")\n",
    "dataset = \"IMDB-BINARY\"\n",
    "print(\"Load from \", base_path)\n",
    "nmis_kpca = {}\n",
    "nmis_tsvd = {}\n",
    "nmis_spec = {}\n",
    "nmis_pred = {}\n",
    "\n",
    "classes = dp.get_dataset(dataset)\n",
    "nmis_kpca[dataset] = []\n",
    "nmis_tsvd[dataset] = []\n",
    "nmis_spec[dataset] = []\n",
    "nmis_pred[dataset] = []\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for iterations in range(1,6):\n",
    "    # 0 taking just the nodelabels themselves into account; \n",
    "     # 1 considers nearest-neighbours, 2 one layer deeper and so on\n",
    "    # play with this parameter to create a new kernel!\n",
    "    print(\"##################################\")\n",
    "    print(\"Dataset \", dataset)\n",
    "    print(\"Iteration \", iterations)\n",
    "    print(\"##################################\")\n",
    "\n",
    "    #Gram Matrix for the Weisfeiler-Lehman subtree kernel\n",
    "    gram = load_csv(os.path.join(base_path,f\"{dataset}_gram_matrix_wl{iterations}.csv\"))\n",
    "    gram = aux.normalize_gram_matrix(gram)\n",
    "\n",
    "    #Sparse Vectors for the Weisfeiler-Lehmann subtree kernel\n",
    "    vec = load_sparse(os.path.join(base_path,f\"{dataset}_vectors_wl{iterations}.npz\"))\n",
    "    print(gram.shape, vec.shape)\n",
    "\n",
    "\"\"\"\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  1\n",
      "----------------------------------\n",
      "PCA(n_components=5)\n",
      "[0.41000563 0.18489879 0.13825097 0.07750716 0.05840446]\n",
      "[168.17585294 112.93687425  97.6568748   73.12058405  63.47339693]\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  2\n",
      "----------------------------------\n",
      "PCA(n_components=5)\n",
      "[0.36728508 0.16073165 0.12350552 0.09286731 0.06894332]\n",
      "[97.25228815 64.33523313 56.39509995 48.90233716 42.13512323]\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  3\n",
      "----------------------------------\n",
      "PCA(n_components=5)\n",
      "[0.31646818 0.14419196 0.12315295 0.10219165 0.05971233]\n",
      "[71.05910538 47.96508769 44.32789587 40.37963756 30.86645245]\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  4\n",
      "----------------------------------\n",
      "PCA(n_components=5)\n",
      "[0.27895136 0.15139078 0.1150423  0.08798912 0.05106174]\n",
      "[58.60895804 43.17670318 37.63817407 32.91654424 25.07538283]\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  5\n",
      "----------------------------------\n",
      "PCA(n_components=5)\n",
      "[0.26301956 0.15090872 0.10357258 0.07615054 0.0446189 ]\n",
      "[52.73352445 39.94385181 33.09140312 28.37456966 21.7196185 ]\n"
     ]
    }
   ],
   "source": [
    "for iterations in range(1,6):\n",
    "    # 0 taking just the nodelabels themselves into account; \n",
    "     # 1 considers nearest-neighbours, 2 one layer deeper and so on\n",
    "    # play with this parameter to create a new kernel!\n",
    "    print(\"\\n##################################\")\n",
    "    print(\"Dataset \", dataset)\n",
    "    print(\"Iteration \", iterations)\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "    #Gram Matrix for the Weisfeiler-Lehman subtree kernel\n",
    "    gram = load_csv(os.path.join(base_path,f\"{dataset}_gram_matrix_wl{iterations}.csv\"))\n",
    "    gram = aux.normalize_gram_matrix(gram)\n",
    "    \n",
    "    # apply PCA\n",
    "    pca = PCA(n_components = 5)\n",
    "    pca.fit(gram)\n",
    "    print(pca.fit(gram))\n",
    "    print(pca.explained_variance_ratio_)\n",
    "    print(pca.singular_values_)\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  1\n",
      "----------------------------------\n",
      "algorithm      -  AgglomerativeClustering()\n",
      "clustering nmi -  0.03564147172482907\n",
      "----------------------------------\n",
      "algorithm      -  DBSCAN(eps=1, min_samples=1)\n",
      "clustering nmi -  0.1469800867528924\n",
      "----------------------------------\n",
      "algorithm      -  FeatureAgglomeration(n_clusters=1000)\n",
      "clustering nmi -  0.18238549547225852\n",
      "----------------------------------\n",
      "algorithm      -  KMeans(max_iter=5, n_clusters=500)\n",
      "clustering nmi -  0.14799752230619395\n",
      "----------------------------------\n",
      "algorithm      -  AffinityPropagation(max_iter=50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_affinity_propagation.py:152: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 0.25 which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_affinity_propagation.py:244: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  \"will not have any cluster centers.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering nmi -  0.0\n",
      "----------------------------------\n",
      "algorithm      -  SpectralClustering(affinity='precomputed')\n",
      "clustering nmi -  0.08932857822930954\n",
      "----------------------------------\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  2\n",
      "----------------------------------\n",
      "algorithm      -  AgglomerativeClustering()\n",
      "clustering nmi -  0.029737379686157094\n",
      "----------------------------------\n",
      "algorithm      -  DBSCAN(eps=1, min_samples=1)\n",
      "clustering nmi -  0.15253556696059112\n",
      "----------------------------------\n",
      "algorithm      -  FeatureAgglomeration(n_clusters=1000)\n",
      "clustering nmi -  0.18238549547225852\n",
      "----------------------------------\n",
      "algorithm      -  KMeans(max_iter=5, n_clusters=500)\n",
      "clustering nmi -  0.15122504230295059\n",
      "----------------------------------\n",
      "algorithm      -  AffinityPropagation(max_iter=50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_affinity_propagation.py:152: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 0.25 which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_affinity_propagation.py:244: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  \"will not have any cluster centers.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering nmi -  0.0\n",
      "----------------------------------\n",
      "algorithm      -  SpectralClustering(affinity='precomputed')\n",
      "clustering nmi -  0.08665402678177929\n",
      "----------------------------------\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  3\n",
      "----------------------------------\n",
      "algorithm      -  AgglomerativeClustering()\n",
      "clustering nmi -  0.03477377129286145\n",
      "----------------------------------\n",
      "algorithm      -  DBSCAN(eps=1, min_samples=1)\n",
      "clustering nmi -  0.15320552867850715\n",
      "----------------------------------\n",
      "algorithm      -  FeatureAgglomeration(n_clusters=1000)\n",
      "clustering nmi -  0.18238549547225852\n",
      "----------------------------------\n",
      "algorithm      -  KMeans(max_iter=5, n_clusters=500)\n",
      "clustering nmi -  0.1500573620212832\n",
      "----------------------------------\n",
      "algorithm      -  AffinityPropagation(max_iter=50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_affinity_propagation.py:152: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 0.25 which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_affinity_propagation.py:244: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  \"will not have any cluster centers.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering nmi -  0.0\n",
      "----------------------------------\n",
      "algorithm      -  SpectralClustering(affinity='precomputed')\n",
      "clustering nmi -  0.08799650871638601\n",
      "----------------------------------\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  4\n",
      "----------------------------------\n",
      "algorithm      -  AgglomerativeClustering()\n",
      "clustering nmi -  0.02389012035992634\n",
      "----------------------------------\n",
      "algorithm      -  DBSCAN(eps=1, min_samples=1)\n",
      "clustering nmi -  0.15407689467658953\n",
      "----------------------------------\n",
      "algorithm      -  FeatureAgglomeration(n_clusters=1000)\n",
      "clustering nmi -  0.18238549547225852\n",
      "----------------------------------\n",
      "algorithm      -  KMeans(max_iter=5, n_clusters=500)\n",
      "clustering nmi -  0.15057950834894768\n",
      "----------------------------------\n",
      "algorithm      -  AffinityPropagation(max_iter=50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_affinity_propagation.py:152: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 0.25 which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_affinity_propagation.py:244: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  \"will not have any cluster centers.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering nmi -  0.0\n",
      "----------------------------------\n",
      "algorithm      -  SpectralClustering(affinity='precomputed')\n",
      "clustering nmi -  0.08737337620083317\n",
      "----------------------------------\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  5\n",
      "----------------------------------\n",
      "algorithm      -  AgglomerativeClustering()\n",
      "clustering nmi -  0.02389012035992634\n",
      "----------------------------------\n",
      "algorithm      -  DBSCAN(eps=1, min_samples=1)\n",
      "clustering nmi -  0.15394363336821526\n",
      "----------------------------------\n",
      "algorithm      -  FeatureAgglomeration(n_clusters=1000)\n",
      "clustering nmi -  0.18238549547225852\n",
      "----------------------------------\n",
      "algorithm      -  KMeans(max_iter=5, n_clusters=500)\n",
      "clustering nmi -  0.14981490068097986\n",
      "----------------------------------\n",
      "algorithm      -  AffinityPropagation(max_iter=50)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_affinity_propagation.py:152: FutureWarning: 'random_state' has been introduced in 0.23. It will be set to None starting from 0.25 which means that results will differ at every function call. Set 'random_state' to None to silence this warning, or to 0 to keep the behavior of versions <0.23.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering nmi -  0.0\n",
      "----------------------------------\n",
      "algorithm      -  SpectralClustering(affinity='precomputed')\n",
      "clustering nmi -  0.08675752131102306\n",
      "----------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/cluster/_affinity_propagation.py:244: ConvergenceWarning: Affinity propagation did not converge, this model will not have any cluster centers.\n",
      "  \"will not have any cluster centers.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "for iterations in range(1,6):\n",
    "    # 0 taking just the nodelabels themselves into account; \n",
    "     # 1 considers nearest-neighbours, 2 one layer deeper and so on\n",
    "    # play with this parameter to create a new kernel!\n",
    "    print(\"\\n##################################\")\n",
    "    print(\"Dataset \", dataset)\n",
    "    print(\"Iteration \", iterations)\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "    #Gram Matrix for the Weisfeiler-Lehman subtree kernel\n",
    "    gram = load_csv(os.path.join(base_path,f\"{dataset}_gram_matrix_wl{iterations}.csv\"))\n",
    "    gram = aux.normalize_gram_matrix(gram)\n",
    "    \n",
    "    \n",
    "    cluster_algorithms = [\n",
    "        AgglomerativeClustering(),\n",
    "        DBSCAN(eps=1, min_samples=1),\n",
    "        FeatureAgglomeration(n_clusters=1000),\n",
    "        KMeans(n_clusters=500, max_iter=5),\n",
    "        SpectralClustering(affinity='precomputed')\n",
    "    ]\n",
    "    \n",
    "    for algorithm in cluster_algorithms:\n",
    "        print('algorithm      - ', algorithm)\n",
    "        clustering = algorithm.fit(gram)\n",
    "        nmi_score = normalized_mutual_info_score(clustering.labels_, classes)\n",
    "        print('clustering nmi - ', nmi_score)\n",
    "        print(\"----------------------------------\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  1\n",
      "----------------------------------\n",
      "LocalOutlierFactor(n_neighbors=100)\n",
      "len(classes) 1000\n",
      "number of errors =  500\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  2\n",
      "----------------------------------\n",
      "LocalOutlierFactor(n_neighbors=100)\n",
      "len(classes) 1000\n",
      "number of errors =  500\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  3\n",
      "----------------------------------\n",
      "LocalOutlierFactor(n_neighbors=100)\n",
      "len(classes) 1000\n",
      "number of errors =  509\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  4\n",
      "----------------------------------\n",
      "LocalOutlierFactor(n_neighbors=100)\n",
      "len(classes) 1000\n",
      "number of errors =  539\n",
      "\n",
      "##################################\n",
      "Dataset  IMDB-BINARY\n",
      "Iteration  5\n",
      "----------------------------------\n",
      "LocalOutlierFactor(n_neighbors=100)\n",
      "len(classes) 1000\n",
      "number of errors =  585\n"
     ]
    }
   ],
   "source": [
    "for iterations in range(1,6):\n",
    "    # 0 taking just the nodelabels themselves into account; \n",
    "     # 1 considers nearest-neighbours, 2 one layer deeper and so on\n",
    "    # play with this parameter to create a new kernel!\n",
    "    print(\"\\n##################################\")\n",
    "    print(\"Dataset \", dataset)\n",
    "    print(\"Iteration \", iterations)\n",
    "    print(\"----------------------------------\")\n",
    "\n",
    "    #Gram Matrix for the Weisfeiler-Lehman subtree kernel\n",
    "    gram = load_csv(os.path.join(base_path,f\"{dataset}_gram_matrix_wl{iterations}.csv\"))\n",
    "    gram = aux.normalize_gram_matrix(gram)\n",
    "    \n",
    "    \n",
    "    \n",
    "    lof = LocalOutlierFactor(n_neighbors=100)\n",
    "    lof_pred = lof.fit_predict(gram)\n",
    "    print(lof)\n",
    "    # print(lof.negative_outlier_factor_)\n",
    "    \n",
    "    print(\"len(classes)\", len(classes))\n",
    "    \n",
    "    n_errors = (lof_pred != classes).sum()\n",
    "    print(\"number of errors = \", n_errors)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize and interpret your results\n",
    "\n",
    "IMDB-BINARY data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(G, color=None, figsize=(5,5)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    nx.draw_networkx(G, \n",
    "                     pos=nx.spring_layout(G, seed=42),\n",
    "                     with_labels=True,\n",
    "                     node_color=color,\n",
    "                     cmap=\"Set2\")\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs in data set is 1000\n",
      "Number of classes 2\n"
     ]
    }
   ],
   "source": [
    "base_path = os.path.join(\"kernels\", \"without_labels\")\n",
    "ds_name = \"IMDB-BINARY\"\n",
    "classes = dp.get_dataset(ds_name)\n",
    "G = tud_to_networkx(ds_name)\n",
    "print(f\"Number of graphs in data set is {len(G)}\")\n",
    "print(f\"Number of classes {len(set(classes.tolist()))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DM_Assignment_Graph_Kernels.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
